{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt install -y ocl-icd-opencl-dev pocl-opencl-icd clinfo"
      ],
      "metadata": {
        "id": "zIx1CYUEzT8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPD_dYR4yp3m",
        "outputId": "afb4f39a-6f88-4088-a279-081da5d9f78c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting reduction.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduction.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "const int N = 1 << 20;\n",
        "const int BLOCK_SIZE = 256;\n",
        "\n",
        "// Макрос для проверки ошибок CUDA\n",
        "#define CUDA_CHECK(call)                                   \\\n",
        "    do {                                                   \\\n",
        "        cudaError_t err = call;                            \\\n",
        "        if (err != cudaSuccess) {                          \\\n",
        "            cout << \"CUDA ошибка: \"                        \\\n",
        "                 << cudaGetErrorString(err) << endl;      \\\n",
        "            return 1;                                      \\\n",
        "        }                                                  \\\n",
        "    } while (0)\n",
        "\n",
        "__global__ void reductionKernel(const float* input, float* partial, int n) {\n",
        "    __shared__ float sharedData[BLOCK_SIZE];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx < n) {\n",
        "        sharedData[tid] = input[idx];\n",
        "    } else {\n",
        "        sharedData[tid] = 0.0f;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            sharedData[tid] += sharedData[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) {\n",
        "        partial[blockIdx.x] = sharedData[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float* h_data = new float[N];\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_data[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    float cpuSum = 0.0f;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        cpuSum += h_data[i];\n",
        "    }\n",
        "\n",
        "    float *d_data, *d_partial;\n",
        "\n",
        "    int gridSize = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "    CUDA_CHECK(cudaMalloc(&d_data, N * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_partial, gridSize * sizeof(float)));\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(d_data, h_data,\n",
        "                           N * sizeof(float),\n",
        "                           cudaMemcpyHostToDevice));\n",
        "\n",
        "    reductionKernel<<<gridSize, BLOCK_SIZE>>>(d_data, d_partial, N);\n",
        "\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "    float* h_partial = new float[gridSize];\n",
        "    CUDA_CHECK(cudaMemcpy(h_partial, d_partial,\n",
        "                           gridSize * sizeof(float),\n",
        "                           cudaMemcpyDeviceToHost));\n",
        "\n",
        "    float gpuSum = 0.0f;\n",
        "    for (int i = 0; i < gridSize; i++) {\n",
        "        gpuSum += h_partial[i];\n",
        "    }\n",
        "\n",
        "    cout << \"Сумма на CPU: \" << cpuSum << endl;\n",
        "    cout << \"Сумма на GPU: \" << gpuSum << endl;\n",
        "\n",
        "    if (abs(cpuSum - gpuSum) < 1e-3) {\n",
        "        cout << \"Результат корректен\" << endl;\n",
        "    } else {\n",
        "        cout << \"Ошибка в вычислениях\" << endl;\n",
        "    }\n",
        "\n",
        "    delete[] h_data;\n",
        "    delete[] h_partial;\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(d_partial);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 reduction.cu -o reduction\n",
        "!./reduction\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-f9JA36y-sX",
        "outputId": "83ac4064-f53b-4be5-9158-9996bee088f0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сумма на CPU: 1.04858e+06\n",
            "Сумма на GPU: 1.04858e+06\n",
            "Результат корректен\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prefix_sum.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// Размер массива (один блок)\n",
        "const int N = 256;\n",
        "\n",
        "// CUDA-ядро префиксной суммы с использованием shared memory\n",
        "__global__ void prefixSumKernel(const float* input, float* output) {\n",
        "    __shared__ float temp[N];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "\n",
        "    // Загрузка данных в shared memory\n",
        "    temp[tid] = input[tid];\n",
        "    __syncthreads();\n",
        "\n",
        "    // Алгоритм префиксной суммы (Hillis-Steele)\n",
        "    for (int offset = 1; offset < N; offset <<= 1) {\n",
        "        float value = 0.0f;\n",
        "        if (tid >= offset) {\n",
        "            value = temp[tid - offset];\n",
        "        }\n",
        "        __syncthreads();\n",
        "        temp[tid] += value;\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Запись результата в глобальную память\n",
        "    output[tid] = temp[tid];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float h_input[N];\n",
        "    float h_output[N];\n",
        "    float h_cpu[N];\n",
        "\n",
        "    // Инициализация массива\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_input[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    // Последовательная префиксная сумма на CPU\n",
        "    h_cpu[0] = h_input[0];\n",
        "    for (int i = 1; i < N; i++) {\n",
        "        h_cpu[i] = h_cpu[i - 1] + h_input[i];\n",
        "    }\n",
        "\n",
        "    float *d_input, *d_output;\n",
        "    cudaMalloc(&d_input, N * sizeof(float));\n",
        "    cudaMalloc(&d_output, N * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_input, h_input, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Запуск ядра (один блок)\n",
        "    prefixSumKernel<<<1, N>>>(d_input, d_output);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(h_output, d_output, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Проверка корректности\n",
        "    bool correct = true;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        if (abs(h_output[i] - h_cpu[i]) > 1e-5) {\n",
        "            correct = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    cout << \"Первые 10 элементов результата:\\n\";\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        cout << h_output[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    if (correct) {\n",
        "        cout << \"Результат корректен\" << endl;\n",
        "    } else {\n",
        "        cout << \"Ошибка в вычислениях\" << endl;\n",
        "    }\n",
        "\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp6jZNe2z28u",
        "outputId": "87d74ceb-1cad-4244-854f-4b6c7689a42f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing prefix_sum.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 prefix_sum.cu -o prefix_sum\n",
        "!./prefix_sum\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LqRhklhz9Zz",
        "outputId": "84bfd258-10bd-471e-8cb1-6b09180330bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Первые 10 элементов результата:\n",
            "1 2 3 4 5 6 7 8 9 10 \n",
            "Результат корректен\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile performance_analysis.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono>\n",
        "\n",
        "using namespace std;\n",
        "using namespace chrono;\n",
        "\n",
        "const int BLOCK_SIZE = 256;\n",
        "\n",
        "__global__ void reductionKernel(const float* input, float* partial, int n) {\n",
        "    __shared__ float data[BLOCK_SIZE];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * blockDim.x + tid;\n",
        "\n",
        "    data[tid] = (idx < n) ? input[idx] : 0.0f;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            data[tid] += data[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) {\n",
        "        partial[blockIdx.x] = data[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "void cpuReduction(const float* data, int n) {\n",
        "    volatile float sum = 0.0f;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        sum += data[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int sizes[] = {1024, 16384, 262144, 1048576};\n",
        "\n",
        "    for (int s = 0; s < 4; s++) {\n",
        "        int N = sizes[s];\n",
        "        cout << \"\\nРазмер массива: \" << N << endl;\n",
        "\n",
        "        float* h_data = new float[N];\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            h_data[i] = 1.0f;\n",
        "        }\n",
        "\n",
        "        float *d_data, *d_partial;\n",
        "        int gridSize = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "        cudaMalloc(&d_data, N * sizeof(float));\n",
        "        cudaMalloc(&d_partial, gridSize * sizeof(float));\n",
        "        cudaMemcpy(d_data, h_data, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "        // GPU тайминг\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        reductionKernel<<<gridSize, BLOCK_SIZE>>>(d_data, d_partial, N);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        float gpuTime;\n",
        "        cudaEventElapsedTime(&gpuTime, start, stop);\n",
        "\n",
        "        // CPU тайминг\n",
        "        auto cpuStart = high_resolution_clock::now();\n",
        "        cpuReduction(h_data, N);\n",
        "        auto cpuEnd = high_resolution_clock::now();\n",
        "        double cpuTime = duration<double, milli>(cpuEnd - cpuStart).count();\n",
        "\n",
        "        cout << \"CPU редукция: \" << cpuTime << \" мс\" << endl;\n",
        "        cout << \"GPU редукция: \" << gpuTime << \" мс\" << endl;\n",
        "\n",
        "        delete[] h_data;\n",
        "        cudaFree(d_data);\n",
        "        cudaFree(d_partial);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdZuHeI40WPn",
        "outputId": "7bb4c339-2f68-411b-e6ae-e0fe2952c2be"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing performance_analysis.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 performance_analysis.cu -o perf\n",
        "!./perf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6I42ZR30dDx",
        "outputId": "4c4d7e5f-8d5e-42bd-e854-6b150686ff94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Размер массива: 1024\n",
            "CPU редукция: 0.003718 мс\n",
            "GPU редукция: 0.12304 мс\n",
            "\n",
            "Размер массива: 16384\n",
            "CPU редукция: 0.054798 мс\n",
            "GPU редукция: 0.012288 мс\n",
            "\n",
            "Размер массива: 262144\n",
            "CPU редукция: 0.85823 мс\n",
            "GPU редукция: 0.033152 мс\n",
            "\n",
            "Размер массива: 1048576\n",
            "CPU редукция: 3.60545 мс\n",
            "GPU редукция: 0.10736 мс\n"
          ]
        }
      ]
    }
  ]
}