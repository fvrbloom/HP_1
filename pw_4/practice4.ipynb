{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0JQHGLzCI5T",
        "outputId": "f946aaac-9497-4b2f-dc42-76f8afe1842c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing task1.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile task1.cu\n",
        "#include <iostream>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// Размер массива\n",
        "const int N = 1'000'000;\n",
        "\n",
        "int main() {\n",
        "    // Инициализация генератора случайных чисел\n",
        "    srand(static_cast<unsigned int>(time(nullptr)));\n",
        "\n",
        "    // Выделение памяти под массив\n",
        "    int* data = new int[N];\n",
        "\n",
        "    // Генерация случайных чисел\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        data[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    // Контрольный вывод первых элементов\n",
        "    cout << \"Первые 10 элементов массива:\\n\";\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        cout << data[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    // Освобождение памяти\n",
        "    delete[] data;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc task1.cu -o task1\n",
        "!./task1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfhitIafCkCQ",
        "outputId": "d3fe2065-2fd2-4167-9e14-1f4dc1e17209"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Первые 10 элементов массива:\n",
            "77 31 80 42 54 16 3 3 57 25 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task2.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono>\n",
        "\n",
        "using namespace std;\n",
        "using namespace chrono;\n",
        "\n",
        "// Размер массива\n",
        "const int N = 1'000'000;\n",
        "\n",
        "// Размер блока потоков\n",
        "const int BLOCK_SIZE = 256;\n",
        "\n",
        "//  Вариант A\n",
        "// Редукция с использованием только глобальной памяти.\n",
        "// Каждый поток читает данные напрямую из global memory.\n",
        "__global__ void reductionGlobal(const float* input, float* partial, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx < n) {\n",
        "        partial[idx] = input[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// - Вариант B\n",
        "// Редукция с использованием разделяемой памяти.\n",
        "// Данные блока сначала копируются в shared memory,\n",
        "// затем выполняется суммирование внутри блока.\n",
        "__global__ void reductionShared(const float* input, float* partial, int n) {\n",
        "    __shared__ float sharedData[BLOCK_SIZE];\n",
        "\n",
        "    int globalIdx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int localIdx = threadIdx.x;\n",
        "\n",
        "    if (globalIdx < n) {\n",
        "        sharedData[localIdx] = input[globalIdx];\n",
        "    } else {\n",
        "        sharedData[localIdx] = 0.0f;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (localIdx < stride) {\n",
        "            sharedData[localIdx] += sharedData[localIdx + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (localIdx == 0) {\n",
        "        partial[blockIdx.x] = sharedData[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Выделение памяти на CPU\n",
        "    float* h_data = new float[N];\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_data[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    // Выделение памяти на GPU\n",
        "    float *d_data, *d_partial;\n",
        "    cudaMalloc(&d_data, N * sizeof(float));\n",
        "    cudaMalloc(&d_partial, N * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_data, h_data, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int gridSize = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "    // Глобальная память\n",
        "\n",
        "    auto startGlobal = high_resolution_clock::now();\n",
        "    reductionGlobal<<<gridSize, BLOCK_SIZE>>>(d_data, d_partial, N);\n",
        "    cudaDeviceSynchronize();\n",
        "    auto endGlobal = high_resolution_clock::now();\n",
        "\n",
        "    double timeGlobal =\n",
        "        duration<double, milli>(endGlobal - startGlobal).count();\n",
        "\n",
        "    // Суммирование частичных результатов на CPU\n",
        "    float* h_partial = new float[N];\n",
        "    cudaMemcpy(h_partial, d_partial, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    float sumGlobal = 0.0f;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        sumGlobal += h_partial[i];\n",
        "    }\n",
        "\n",
        "    // Разделяемая память\n",
        "\n",
        "    auto startShared = high_resolution_clock::now();\n",
        "    reductionShared<<<gridSize, BLOCK_SIZE>>>(d_data, d_partial, N);\n",
        "    cudaDeviceSynchronize();\n",
        "    auto endShared = high_resolution_clock::now();\n",
        "\n",
        "    double timeShared =\n",
        "        duration<double, milli>(endShared - startShared).count();\n",
        "\n",
        "    cudaMemcpy(h_partial, d_partial, gridSize * sizeof(float),\n",
        "               cudaMemcpyDeviceToHost);\n",
        "\n",
        "    float sumShared = 0.0f;\n",
        "    for (int i = 0; i < gridSize; i++) {\n",
        "        sumShared += h_partial[i];\n",
        "    }\n",
        "\n",
        "    // Вывод результатов\n",
        "\n",
        "    cout << \"Размер массива: \" << N << \" элементов\\n\";\n",
        "    cout << \"Сумма (global memory): \" << sumGlobal\n",
        "         << \" | Время: \" << timeGlobal << \" мс\\n\";\n",
        "    cout << \"Сумма (shared memory): \" << sumShared\n",
        "         << \" | Время: \" << timeShared << \" мс\\n\";\n",
        "\n",
        "    // Освобождение памяти\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(d_partial);\n",
        "    delete[] h_data;\n",
        "    delete[] h_partial;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_qAnLcjDaJQ",
        "outputId": "434a33db-7d6b-42cc-b8d0-17feb2e8fb19"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing task2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc task2.cu -o task2\n",
        "!./task2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-mARNWRE7FO",
        "outputId": "2a2e4a1a-4e8f-4635-9534-4c2b6c835bf9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер массива: 1000000 элементов\n",
            "Сумма (global memory): 0 | Время: 49.1332 мс\n",
            "Сумма (shared memory): 0 | Время: 0.018966 мс\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task3.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// Размер массива\n",
        "const int N = 1024;\n",
        "\n",
        "// Размер подмассива для пузырьковой сортировки\n",
        "const int SUBARRAY_SIZE = 32;\n",
        "\n",
        "// Этап 1\n",
        "// Пузырьковая сортировка небольших подмассивов.\n",
        "// Используется локальная память потока.\n",
        "__global__ void bubbleSortSubarrays(int* data) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int start = idx * SUBARRAY_SIZE;\n",
        "\n",
        "    if (start + SUBARRAY_SIZE <= N) {\n",
        "        // Локальный массив в памяти потока\n",
        "        int local[SUBARRAY_SIZE];\n",
        "\n",
        "        // Загрузка данных из глобальной памяти\n",
        "        for (int i = 0; i < SUBARRAY_SIZE; i++) {\n",
        "            local[i] = data[start + i];\n",
        "        }\n",
        "\n",
        "        // Пузырьковая сортировка\n",
        "        for (int i = 0; i < SUBARRAY_SIZE - 1; i++) {\n",
        "            for (int j = 0; j < SUBARRAY_SIZE - i - 1; j++) {\n",
        "                if (local[j] > local[j + 1]) {\n",
        "                    int temp = local[j];\n",
        "                    local[j] = local[j + 1];\n",
        "                    local[j + 1] = temp;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Запись результата обратно в глобальную память\n",
        "        for (int i = 0; i < SUBARRAY_SIZE; i++) {\n",
        "            data[start + i] = local[i];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Этап 2\n",
        "// Слияние двух соседних отсортированных подмассивов.\n",
        "// Используется разделяемая память.\n",
        "__global__ void mergeSubarrays(int* data, int* output) {\n",
        "    __shared__ int shared[2 * SUBARRAY_SIZE];\n",
        "\n",
        "    int blockStart = blockIdx.x * 2 * SUBARRAY_SIZE;\n",
        "\n",
        "    // Загрузка данных в shared memory\n",
        "    for (int i = threadIdx.x; i < 2 * SUBARRAY_SIZE; i += blockDim.x) {\n",
        "        shared[i] = data[blockStart + i];\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Слияние выполняется одним потоком блока\n",
        "    if (threadIdx.x == 0) {\n",
        "        int i = 0;\n",
        "        int j = SUBARRAY_SIZE;\n",
        "        int k = blockStart;\n",
        "\n",
        "        while (i < SUBARRAY_SIZE && j < 2 * SUBARRAY_SIZE) {\n",
        "            if (shared[i] < shared[j]) {\n",
        "                output[k++] = shared[i++];\n",
        "            } else {\n",
        "                output[k++] = shared[j++];\n",
        "            }\n",
        "        }\n",
        "\n",
        "        while (i < SUBARRAY_SIZE) {\n",
        "            output[k++] = shared[i++];\n",
        "        }\n",
        "\n",
        "        while (j < 2 * SUBARRAY_SIZE) {\n",
        "            output[k++] = shared[j++];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int* h_data = new int[N];\n",
        "\n",
        "    // Инициализация массива\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_data[i] = rand() % 1000;\n",
        "    }\n",
        "\n",
        "    int* d_data;\n",
        "    int* d_output;\n",
        "    cudaMalloc(&d_data, N * sizeof(int));\n",
        "    cudaMalloc(&d_output, N * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_data, h_data, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Запуск пузырьковой сортировки подмассивов\n",
        "    int numSubarrays = N / SUBARRAY_SIZE;\n",
        "    bubbleSortSubarrays<<<numSubarrays, 1>>>(d_data);\n",
        "\n",
        "    // Запуск слияния подмассивов\n",
        "    int numMerges = N / (2 * SUBARRAY_SIZE);\n",
        "    mergeSubarrays<<<numMerges, SUBARRAY_SIZE>>>(d_data, d_output);\n",
        "\n",
        "    cudaMemcpy(h_data, d_output, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Контрольный вывод первых элементов\n",
        "    cout << \"Первые 10 элементов отсортированного массива:\\n\";\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        cout << h_data[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    // Освобождение памяти\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(d_output);\n",
        "    delete[] h_data;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojFbHPDdFecq",
        "outputId": "2e68f93b-cc9c-4bb1-e5d5-86f4d981449c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting task3.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc task3.cu -o task3\n",
        "!./task3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tddz5KjnFhEg",
        "outputId": "dd85b12c-3c60-4591-ae67-3592bcbb1ad4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Первые 10 элементов отсортированного массива:\n",
            "0 0 0 0 0 0 0 0 0 0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task4.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono>\n",
        "\n",
        "using namespace std;\n",
        "using namespace chrono;\n",
        "\n",
        "// Размер блока\n",
        "const int BLOCK_SIZE = 256;\n",
        "\n",
        "// Редукция с использованием только глобальной памяти\n",
        "__global__ void reductionGlobal(const float* input, float* partial, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        partial[idx] = input[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Редукция с использованием разделяемой памяти\n",
        "__global__ void reductionShared(const float* input, float* partial, int n) {\n",
        "    __shared__ float sharedData[BLOCK_SIZE];\n",
        "\n",
        "    int globalIdx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int localIdx = threadIdx.x;\n",
        "\n",
        "    if (globalIdx < n) {\n",
        "        sharedData[localIdx] = input[globalIdx];\n",
        "    } else {\n",
        "        sharedData[localIdx] = 0.0f;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (localIdx < stride) {\n",
        "            sharedData[localIdx] += sharedData[localIdx + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (localIdx == 0) {\n",
        "        partial[blockIdx.x] = sharedData[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "void runTest(int N) {\n",
        "    float* h_data = new float[N];\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_data[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    float *d_data, *d_partial;\n",
        "    cudaMalloc(&d_data, N * sizeof(float));\n",
        "    cudaMalloc(&d_partial, N * sizeof(float));\n",
        "    cudaMemcpy(d_data, h_data, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int gridSize = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "    auto startGlobal = high_resolution_clock::now();\n",
        "    reductionGlobal<<<gridSize, BLOCK_SIZE>>>(d_data, d_partial, N);\n",
        "    cudaDeviceSynchronize();\n",
        "    auto endGlobal = high_resolution_clock::now();\n",
        "\n",
        "    double timeGlobal =\n",
        "        duration<double, milli>(endGlobal - startGlobal).count();\n",
        "\n",
        "    auto startShared = high_resolution_clock::now();\n",
        "    reductionShared<<<gridSize, BLOCK_SIZE>>>(d_data, d_partial, N);\n",
        "    cudaDeviceSynchronize();\n",
        "    auto endShared = high_resolution_clock::now();\n",
        "\n",
        "    double timeShared =\n",
        "        duration<double, milli>(endShared - startShared).count();\n",
        "\n",
        "    cout << \"Размер массива: \" << N << endl;\n",
        "    cout << \"Global memory: \" << timeGlobal << \" мс\" << endl;\n",
        "    cout << \"Shared memory: \" << timeShared << \" мс\" << endl;\n",
        "    cout << endl;\n",
        "\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(d_partial);\n",
        "    delete[] h_data;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    runTest(10'000);\n",
        "    runTest(100'000);\n",
        "    runTest(1'000'000);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRWZ-4B_F6UO",
        "outputId": "38480b18-772d-4af9-ffdc-0bba11a6d8ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing task4.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc task4.cu -o task4\n",
        "!./task4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG_ISeP8F7m1",
        "outputId": "90fc3e37-fcdd-4b43-ffbf-ac0eda37ccdb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер массива: 10000\n",
            "Global memory: 7.51468 мс\n",
            "Shared memory: 0.00222 мс\n",
            "\n",
            "Размер массива: 100000\n",
            "Global memory: 0.038103 мс\n",
            "Shared memory: 0.001284 мс\n",
            "\n",
            "Размер массива: 1000000\n",
            "Global memory: 0.073338 мс\n",
            "Shared memory: 0.002005 мс\n",
            "\n"
          ]
        }
      ]
    }
  ]
}