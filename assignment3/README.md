# Assignment 3  
## Архитектура GPU и оптимизация CUDA-программ

---

## Цель работы

Целью данного задания является изучение архитектуры GPU и методов оптимизации CUDA-программ, включая использование различных типов памяти, влияние конфигурации блоков потоков и особенности доступа к глобальной памяти.

---

## Среда выполнения

- Среда: Google Colab  
- GPU: NVIDIA Tesla T4  
- Язык программирования: CUDA C++  
- Компиляция: nvcc с указанием архитектуры `sm_75`

---

## Задание 1. Поэлементная обработка массива

### Описание

Реализованы две версии CUDA-программы для поэлементного умножения элементов массива:
1. Реализация с использованием только глобальной памяти.
2. Реализация с использованием разделяемой памяти.

Размер массива — 1 000 000 элементов. Выполнено сравнение времени выполнения обеих реализаций.

### Результаты выполнения

![Output задания 1](output1.png)

### Диаграмма алгоритма

![Диаграмма задания 1](diagram1_ass3.png)

### Вывод

Использование разделяемой памяти позволяет сократить количество обращений к глобальной памяти и повысить производительность по сравнению с реализацией, использующей только глобальную память.

---

## Задание 2. Влияние размера блока потоков

### Описание

Реализована CUDA-программа для поэлементного сложения двух массивов. Проведены замеры времени выполнения для различных размеров блока потоков (например, 128, 256 и 512 потоков).

### Результаты выполнения

![Output задания 2](output2.png)

### Диаграмма алгоритма

![Диаграмма задания 2](diagram2_ass3.png)

### Вывод

Размер блока потоков оказывает существенное влияние на производительность CUDA-программы. Оптимальный размер блока обеспечивает более эффективную загрузку вычислительных ресурсов GPU.

---

## Задание 3. Доступ к глобальной памяти

### Описание

Реализованы две версии CUDA-программы:
- с коалесцированным доступом к глобальной памяти;
- с некоалесцированным доступом к глобальной памяти.

Проведено сравнение времени выполнения для массива размером 1 000 000 элементов.

### Результаты выполнения

![Output задания 3](output3.png)

### Диаграмма алгоритма

![Диаграмма задания 3](diagram3_ass3.png)

### Вывод

Коалесцированный доступ к глобальной памяти обеспечивает более высокую производительность за счёт уменьшения числа транзакций памяти по сравнению с некоалесцированным доступом.

---

## Задание 4. Оптимизация конфигурации сетки и блоков

### Описание

Для одной из реализованных CUDA-программ была выполнена оптимизация параметров конфигурации сетки и блоков потоков. Сравнивалась производительность неоптимальной и оптимизированной конфигураций.

### Результаты выполнения

![Output задания 4](output4.png)

### Диаграмма алгоритма

![Диаграмма задания 4](diagram4_ass3.png)

### Вывод

Оптимальный выбор конфигурации сетки и блоков потоков позволяет значительно повысить производительность CUDA-программы за счёт более эффективного использования ресурсов GPU.

---

## Общие выводы

В ходе выполнения Assignment 3 были изучены ключевые аспекты архитектуры GPU и оптимизации CUDA-программ. Эксперименты показали, что использование разделяемой памяти, коалесцированного доступа к глобальной памяти и корректной конфигурации блоков потоков существенно влияет на производительность параллельных вычислений.

---
